# ğŸ™ï¸ Speech Emotion Recognition using Deep Learning

This project implements a robust Speech Emotion Recognition (SER) system using handcrafted audio features and a 1D Convolutional Neural Network (CNN). It achieves **95.8% accuracy** across four benchmark datasets: **RAVDESS, CREMA-D, TESS,** and **SAVEE**.

---

## ğŸ” Overview

Emotion in speech conveys critical context beyond wordsâ€”key for applications in **virtual assistants**, **mental health monitoring**, **customer service**, and **affective computing**. This project aims to classify speech emotions using signal-processing techniques and a deep learning model optimized for sequence data.

---

## ğŸš€ Key Features

- âœ… **High accuracy (95.8%)** on a merged multi-dataset emotion corpus  
- ğŸ“Š **Feature-based approach** using ZCR, RMS, and MFCC (2376D vector)  
- ğŸ§  **Custom 1D CNN** for sequential feature learning  
- ğŸ”„ **Audio augmentation**: noise, pitch shifting, stretching, time shifting  
- ğŸ§ª Evaluated using confusion matrix and classification reports  

---

## ğŸ“š Datasets Used

| Dataset   | Emotions Covered                            | Speakers       |
|-----------|---------------------------------------------|----------------|
| **RAVDESS**  | Neutral, Calm, Happy, Sad, Angry, Fearful, Disgust, Surprised | 24 (12M, 12F) |
| **CREMA-D** | Angry, Disgust, Fear, Happy, Neutral, Sad | 91 diverse     |
| **TESS**    | Angry, Disgust, Fear, Happy, Neutral, Sad, Surprise | 2F            |
| **SAVEE**   | Angry, Disgust, Fear, Happy, Neutral, Sad, Surprise | 4M            |

Combined total: **7 emotion classes** across **121+ actors**.

---

## ğŸ”¬ Feature Extraction

Extracted using [Librosa](https://librosa.org):
- **Zero-Crossing Rate (ZCR)** â€“ Temporal voicing cues  
- **Root Mean Square (RMS)** â€“ Intensity measure  
- **MFCCs (13)** â€“ Spectral envelope characteristics  

Each 2.5s audio segment â†’ 2376D vector  
All features standardized using `StandardScaler`.

---

## ğŸ§ Data Augmentation

To improve generalization and handle imbalances:
- **Noise injection**  
- **Pitch shifting**
- **Time stretching**
- **Shifting (circular roll)**

Augmentations tripled the dataset size.

---

## ğŸ§  Model Architecture: 1D CNN

```
Input: (2376, 1)
â†’ Conv1D + ReLU + BatchNorm + MaxPool
â†’ Conv1D + ReLU + BatchNorm + MaxPool
â†’ Conv1D + ReLU + BatchNorm + MaxPool
â†’ Flatten
â†’ Dense(512) + ReLU + BatchNorm
â†’ Dense(7) + Softmax
```
* **Optimizer:** RMSprop
* **Loss:** Categorical Crossentropy
* **Callbacks:** EarlyStopping, ReduceLROnPlateau
* **Batch Size:** 64, **Epochs:** 50 (with early stop)
---

## ğŸ“ˆ Results

* ğŸ¯ **Test Accuracy:** `95.8%`
* ğŸ“Š **F1-Score (macro/weighted):** \~`0.96`
* ğŸ“‰ **Minimal overfitting** due to regularization
* âœ… Performs robustly across all datasets


---

## ğŸ“Œ Real-World Applications

* ğŸ§  **Mental health monitoring** (stress, depression detection)
* ğŸ—£ï¸ **Emotion-aware virtual assistants** and chatbots
* ğŸ§“ **Elderly care systems** with emotion-sensitive feedback
* ğŸ® **Emotion-adaptive games and entertainment systems**



---

## ğŸ“Œ Future Work

* ğŸ” Real-time SER deployment using streaming inference
* ğŸ¤ Multimodal SER (e.g. video + speech)
* ğŸ§  Use transformer-based audio backbones (e.g., wav2vec, YAMNet)
* ğŸ“± Mobile optimization (TFLite / Edge deployment)

---






